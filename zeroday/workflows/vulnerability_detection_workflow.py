"""
Main Vulnerability Detection Workflow - NeMo Agent Toolkit integration
"""

import asyncio
from typing import Any, Dict, Optional
from nat.builder.builder import Builder
from nat.cli.register_workflow import register_function
from nat.builder.framework_enum import LLMFrameworkEnum
from nat.profiler.decorators.function_tracking import track_function
from nat.data_models.function import FunctionBaseConfig

from ..agents.orchestration_agent import OrchestrationAgent, OrchestrationConfig


class VulnerabilityDetectionWorkflowConfig(FunctionBaseConfig):
    """Configuration for the vulnerability detection workflow"""
    
    def __init__(
        self,
        repo_url: str,
        orchestration_config: Optional[OrchestrationConfig] = None,
        enable_profiling: bool = True
    ):
        self.repo_url = repo_url
        self.orchestration_config = orchestration_config or OrchestrationConfig(
            name="vulnerability_detection_orchestrator",
            description="Main orchestration agent for vulnerability detection pipeline"
        )
        self.enable_profiling = enable_profiling


async def vulnerability_detection_workflow(
    config: VulnerabilityDetectionWorkflowConfig, 
    builder: Builder
) -> Dict[str, Any]:
    """
    Main vulnerability detection workflow using NeMo Agent Toolkit
    
    This workflow orchestrates the complete vulnerability detection pipeline:
    1. Repository ingestion and preprocessing
    2. Static analysis and pattern detection
    3. Advanced LLM-based vulnerability detection using DeepHat
    4. Report generation and consolidation
    
    Args:
        config: Workflow configuration containing repository URL and settings
        builder: NeMo Builder instance for agent initialization
        
    Returns:
        Dict containing complete pipeline results including vulnerabilities found,
        risk assessment, and generated report files
    """
    
    # Initialize orchestration agent
    orchestration_agent = OrchestrationAgent(config.orchestration_config)
    
    try:
        # Initialize the agent with NeMo builder
        await orchestration_agent.initialize(builder)
        
        # Execute the complete vulnerability detection pipeline
        pipeline_result = await orchestration_agent.execute({
            "repo_url": config.repo_url
        })
        
        return {
            "workflow_status": "success",
            "pipeline_result": pipeline_result,
            "repository_url": config.repo_url,
            "vulnerabilities_found": pipeline_result.get("vulnerability_summary", {}).get("total_vulnerabilities", 0),
            "risk_level": pipeline_result.get("vulnerability_summary", {}).get("overall_risk", "unknown"),
            "report_files": pipeline_result.get("report_files", []),
            "execution_time": pipeline_result.get("execution_time_seconds", 0),
            "agents_executed": pipeline_result.get("agents_executed", []),
            "agents_failed": pipeline_result.get("agents_failed", [])
        }
        
    except Exception as e:
        return {
            "workflow_status": "error",
            "error_message": str(e),
            "repository_url": config.repo_url,
            "vulnerabilities_found": 0,
            "risk_level": "unknown",
            "report_files": [],
            "execution_time": 0,
            "agents_executed": [],
            "agents_failed": ["orchestration_agent"]
        }
        
    finally:
        # Cleanup resources
        try:
            await orchestration_agent.cleanup()
        except Exception as cleanup_error:
            # Log cleanup error but don't fail the workflow
            pass


@track_function(metadata={"workflow_type": "vulnerability_detection", "operation": "main_workflow"})
@register_function(
    config_type=VulnerabilityDetectionWorkflowConfig,
    framework_wrappers=[LLMFrameworkEnum.LANGCHAIN]
)
async def vulnerability_detection_workflow_registered(
    config: VulnerabilityDetectionWorkflowConfig, 
    builder: Builder
):
    """Registered wrapper for the vulnerability detection workflow"""
    result = await vulnerability_detection_workflow(config, builder)
    yield result


class VulnerabilityDetectionWorkflow:
    """
    High-level wrapper for the vulnerability detection workflow
    
    Provides a simple interface for running vulnerability detection on repositories
    with built-in NeMo Agent Toolkit integration, profiling, and error handling.
    """
    
    def __init__(self, enable_profiling: bool = True):
        self.enable_profiling = enable_profiling
        self.builder: Optional[Builder] = None
    
    async def initialize(self, builder: Builder) -> None:
        """Initialize the workflow with NeMo Builder"""
        self.builder = builder
    
    @track_function(metadata={"workflow_type": "vulnerability_detection", "operation": "analyze_repository"})
    async def analyze_repository(
        self, 
        repo_url: str,
        orchestration_config: Optional[OrchestrationConfig] = None
    ) -> Dict[str, Any]:
        """
        Analyze a repository for vulnerabilities
        
        Args:
            repo_url: URL of the repository to analyze
            orchestration_config: Optional custom orchestration configuration
            
        Returns:
            Dict containing analysis results
        """
        if not self.builder:
            raise RuntimeError("Workflow not initialized. Call initialize() first.")
        
        # Create workflow configuration
        workflow_config = VulnerabilityDetectionWorkflowConfig(
            repo_url=repo_url,
            orchestration_config=orchestration_config,
            enable_profiling=self.enable_profiling
        )
        
        # Execute the workflow
        return await vulnerability_detection_workflow(workflow_config, self.builder)
    
    @track_function(metadata={"workflow_type": "vulnerability_detection", "operation": "batch_analyze"})
    async def analyze_repositories_batch(
        self, 
        repo_urls: list[str],
        max_concurrent: int = 3,
        orchestration_config: Optional[OrchestrationConfig] = None
    ) -> Dict[str, Any]:
        """
        Analyze multiple repositories concurrently
        
        Args:
            repo_urls: List of repository URLs to analyze
            max_concurrent: Maximum number of concurrent analyses
            orchestration_config: Optional custom orchestration configuration
            
        Returns:
            Dict containing batch analysis results
        """
        if not self.builder:
            raise RuntimeError("Workflow not initialized. Call initialize() first.")
        
        # Create semaphore to limit concurrent executions
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def analyze_single_repo(repo_url: str) -> Dict[str, Any]:
            async with semaphore:
                return await self.analyze_repository(repo_url, orchestration_config)
        
        # Execute analyses concurrently
        tasks = [analyze_single_repo(url) for url in repo_urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        successful_analyses = []
        failed_analyses = []
        total_vulnerabilities = 0
        
        for i, result in enumerate(results):
            repo_url = repo_urls[i]
            
            if isinstance(result, Exception):
                failed_analyses.append({
                    "repository_url": repo_url,
                    "error": str(result)
                })
            else:
                if result.get("workflow_status") == "success":
                    successful_analyses.append(result)
                    total_vulnerabilities += result.get("vulnerabilities_found", 0)
                else:
                    failed_analyses.append({
                        "repository_url": repo_url,
                        "error": result.get("error_message", "Unknown error")
                    })
        
        return {
            "batch_status": "completed",
            "total_repositories": len(repo_urls),
            "successful_analyses": len(successful_analyses),
            "failed_analyses": len(failed_analyses),
            "total_vulnerabilities_found": total_vulnerabilities,
            "results": successful_analyses,
            "failures": failed_analyses
        }
    
    def get_workflow_info(self) -> Dict[str, Any]:
        """Get information about the workflow configuration"""
        return {
            "workflow_name": "Vulnerability Detection Workflow",
            "description": "Multi-agent pipeline for detecting zero-day vulnerabilities in Python repositories",
            "agents": [
                "Repository Ingestion Agent",
                "Python Analysis Agent", 
                "DeepHat Security Agent",
                "Report Generation Agent"
            ],
            "features": [
                "GitHub repository cloning and preprocessing",
                "Static code analysis and pattern detection",
                "Advanced LLM-based vulnerability detection",
                "Zero-day pattern recognition",
                "Comprehensive report generation",
                "NeMo Agent Toolkit integration",
                "Built-in profiling and observability"
            ],
            "supported_languages": ["Python"],
            "output_formats": ["JSON", "HTML", "TXT"],
            "profiling_enabled": self.enable_profiling,
            "initialized": self.builder is not None
        }


# Convenience function for simple usage
async def analyze_repository_simple(
    repo_url: str, 
    builder: Builder,
    enable_profiling: bool = True
) -> Dict[str, Any]:
    """
    Simple convenience function to analyze a single repository
    
    Args:
        repo_url: Repository URL to analyze
        builder: NeMo Builder instance
        enable_profiling: Whether to enable profiling
        
    Returns:
        Analysis results
    """
    workflow = VulnerabilityDetectionWorkflow(enable_profiling=enable_profiling)
    await workflow.initialize(builder)
    return await workflow.analyze_repository(repo_url)
